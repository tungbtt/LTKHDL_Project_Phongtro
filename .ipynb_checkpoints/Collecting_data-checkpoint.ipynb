{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19505058",
   "metadata": {},
   "source": [
    "# ĐỒ ÁN: LẬP TRÌNH CHO KHOA HỌC DỮ LIỆU\n",
    "## Chủ đề: **Giá phòng trọ ở khu vực Hồ Chí Minh**\n",
    "- Môn học: Lập Trình Cho Khoa Học Dữ Liệu\n",
    "- Nhóm: 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e0924d",
   "metadata": {},
   "source": [
    "## THU THẬP DỮ LIỆU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be13623f",
   "metadata": {},
   "source": [
    "### 1. Cài đặt thư viện, import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4acba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scrapy\n",
    "!pip install spider3\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619ed704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62ff60",
   "metadata": {},
   "source": [
    "### 2. Tạo project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45553f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy startproject phongtro123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fe732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ParaboY\\Desktop\\LTKHDL_Project_Phongtro\\phongtro123\\phongtro123\n"
     ]
    }
   ],
   "source": [
    "cd phongtro123\\phongtro123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d1935",
   "metadata": {},
   "source": [
    "#### 2.1. Thu thập URL của các bài post cho thuê nhà ở Hồ Chí Minh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6e50a",
   "metadata": {},
   "source": [
    "Code trong file `spiders/collect_url.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "\n",
    "class Phongtro123Spider(scrapy.Spider):\n",
    "    name = 'phongtro123_get_url'\n",
    "    start_urls = ['https://phongtro123.com/tinh-thanh/ho-chi-minh?page=1']\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.page_count = 1\n",
    "        self.end_page =0\n",
    "\n",
    "    def parse(self, response):\n",
    "        for item in response.css('div.post-meta'):\n",
    "            link=item.css('a::attr(href)').get()\n",
    "            if link!=None:\n",
    "                yield {\n",
    "                    'link':'https://phongtro123.com'+ link\n",
    "                }\n",
    "            #print(link)\n",
    "        \n",
    "        if self.page_count == 1:\n",
    "            end_page = response.css('#left-col > ul > li:nth-child(6) > a').attrib['href']\n",
    "            end_page=int(re.findall('[0-9]+',end_page)[-1])\n",
    "            self.end_page=end_page\n",
    "        \n",
    "        self.page_count=self.page_count+1\n",
    "        if self.page_count<=self.end_page:\n",
    "            next_page='https://phongtro123.com/tinh-thanh/ho-chi-minh?page='+ str(self.page_count)\n",
    "            yield scrapy.Request(response.urljoin(next_page), callback=self.parse)\n",
    "            \n",
    "        print('Number of page:'+str(end_page))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f71a95",
   "metadata": {},
   "source": [
    "#### 2.2. Thu thập các thông tin trên từng bài post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525245f",
   "metadata": {},
   "source": [
    "Các trường thông tin thu thập trên mỗi bài post:\n",
    "- **Id**: Mã tin quảng cáo cho thuê trọ.\n",
    "- **Title**: Tiêu đề tin quảng cáo cho thuê trọ .\n",
    "- **Address**: Địa chỉ cho thuê trọ.\n",
    "- **Price**: Mức giá cho thuê trọ.\n",
    "- **Acreage**: Diện tích phòng trọ.\n",
    "- **Content**: Thông tin mô tả phòng trọ.\n",
    "- **Type_post**: Loại tin rao quảng cáo.\n",
    "- **Tenant**: Đối tượng có thể thuê trọ.\n",
    "- **Posting_time**: Thời gian đăng thông báo cho thuê trọ.\n",
    "- **End_time**: Thời gian kết thúc cho thuê trọ.\n",
    "- **Contact**: Tên người có thể liên hệ nếu khách muốn thuê trọ.\n",
    "- **Phone_number**: Số điện thoại người liên hệ.\n",
    "- **Zalo**: Số Zalo người liên hệ.\n",
    "- **Link**: Link của bài post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49354d",
   "metadata": {},
   "source": [
    "Code trong file `spiders/collect_info.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbafbdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import scrapy\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import unidecode\n",
    "\n",
    "def remove_accent(text):\n",
    "    if text==None:\n",
    "        return \"\"\n",
    "    return unidecode.unidecode(text)\n",
    "\n",
    "def listToString(s):\n",
    " \n",
    "    # initialize an empty string\n",
    "    str1 = \"\"\n",
    " \n",
    "    # traverse in the string\n",
    "    for ele in s:\n",
    "        str1 += ele + ' || '\n",
    " \n",
    "    # return string\n",
    "    return str1\n",
    "\n",
    "class collect_player_info(scrapy.Spider):\n",
    "    name='phongtro123_get_info'\n",
    "  \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            with open('post_url_temp.json') as f:\n",
    "                self.urls = json.load(f)\n",
    "                self.url_count = 1\n",
    "                self.url=''\n",
    "        except IOError:\n",
    "            print(\"File not found\")\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = self.urls[0]['link']\n",
    "        self.url=urls\n",
    "        yield scrapy.Request(url=urls, callback=self.parse)\n",
    "  \n",
    "    def parse(self, response):\n",
    "        \n",
    "        info={}        \n",
    "\n",
    "        \n",
    "        title=response.xpath('//*[@id=\"left-col\"]/article/header/h1/a/text()').extract_first()\n",
    "        info['title']=remove_accent(title)\n",
    "        \n",
    "        address=response.xpath('//*[@id=\"left-col\"]/article/header/address/text()').extract_first()\n",
    "        info['address']=remove_accent(address)\n",
    "        \n",
    "        price=response.xpath('//*[@id=\"left-col\"]/article/header/div[2]/div[1]/span/text()').extract_first()\n",
    "        info['price']=remove_accent(price)\n",
    "        \n",
    "        acreage=response.xpath('//*[@id=\"left-col\"]/article/header/div[2]/div[2]/span/text()').extract_first()\n",
    "        info['acreage']=remove_accent(acreage)\n",
    "        \n",
    "        \n",
    "        content=' || '.join(response.css('#left-col > article > section.section.post-main-content > div.section-content p::text').getall())\n",
    "        info['content']=remove_accent(content)\n",
    "             \n",
    "        \n",
    "        table = response.xpath('//*[@id=\"left-col\"]/article/section[2]/div[2]/table/tr')\n",
    "        s=remove_accent(table.get())\n",
    "        \n",
    "        match=re.search(r'Ma tin:</td><td>#([^<]+)',s)\n",
    "        if match:\n",
    "            info['id']=match.group(1)\n",
    "        else:\n",
    "            info['id']=None\n",
    "            \n",
    "        match=re.search(r'Loai tin rao:</td><td>([^<]+)',s)\n",
    "        if match:\n",
    "            info['type_post']=match.group(1)\n",
    "        else:\n",
    "            info['type_post']=None\n",
    "            \n",
    "        match=re.search(r'Doi tuong thue:</td><td>([^<]+)',s)\n",
    "        if match:\n",
    "            info['tenant']=match.group(1)\n",
    "        else:\n",
    "            info['tenant']=None\n",
    "            \n",
    "        match=re.search(r'Ngay dang:</td><td><time title=\"([^\"]+)\">',s)\n",
    "        if match:\n",
    "            info['posting_time']=match.group(1)\n",
    "        else:\n",
    "            info['posting_time']=None\n",
    "            \n",
    "        match=re.search(r'Ngay het han:</td><td><time title=\"([^\"]+)\">',s)\n",
    "        if match:\n",
    "            info['end_time']=match.group(1)\n",
    "        else:\n",
    "            info['end_time']=None\n",
    "            \n",
    "        match=re.search(r'Lien he:</td><td> ([^<]+)',s)\n",
    "        if match:\n",
    "            info['contact']=match.group(1)\n",
    "        else:\n",
    "            info['contact']=None\n",
    "            \n",
    "        match=re.search(r'Dien thoai:</td><td> ([^<]+)',s)\n",
    "        if match:\n",
    "            info['phone_number']=match.group(1)\n",
    "        else:\n",
    "            info['phone_number']=None\n",
    "            \n",
    "        match=re.search(r'Zalo</td><td> ([^<]+)',s)\n",
    "        if match:\n",
    "            info['zalo']=match.group(1)\n",
    "        else:\n",
    "            info['zalo']=None\n",
    "        \n",
    "        info['link']=self.url\n",
    "        #info['type_post']=re.search(r'Loai tin rao:</td><td>([^<]+)',s).group(1)\n",
    "        #info['tenant']=re.search(r'Doi tuong thue:</td><td>([^<]+)',s).group(1)\n",
    "        \n",
    "        #info['posting_time']=re.search(r'Ngay dang:</td><td><time title=\"([^\"]+)\">', s).group(1)\n",
    "        #info['end_time']=re.search(r'Ngay het han:</td><td><time title=\"([^\"]+)\">', s).group(1)\n",
    "        #info['contact']=re.search(r'Lien he:</td><td> ([^<]+)', s).group(1)\n",
    "        #info['phone_number']=re.search(r'Dien thoai:</td><td> ([^<]+)', s).group(1)     \n",
    "        #info['zalo']=re.search(r'Zalo</td><td> ([^<]+)', s).group(1)  \n",
    "        #print(info)\n",
    "        \n",
    "        yield info\n",
    "      \n",
    "        if self.url_count < len(self.urls):\n",
    "            next_page_url = self.urls[self.url_count]['link']\n",
    "            self.url=next_page_url\n",
    "            self.url_count += 1\n",
    "            yield scrapy.Request(response.urljoin(next_page_url), callback=self.parse) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef0b1e1",
   "metadata": {},
   "source": [
    "### 3. Scraping data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b07ff6",
   "metadata": {},
   "source": [
    "#### 3.1. Thu thập link các bài post ở Hồ Chí Minh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72406a",
   "metadata": {},
   "source": [
    "Thu thập dữ liệu và ghi vào file `dataset/post_url.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_url -o dataset/post_url.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27a8a2",
   "metadata": {},
   "source": [
    "Loại bỏ trùng lặp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4bf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(r'dataset/post_url.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e175ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af15383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d79393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977a208",
   "metadata": {},
   "source": [
    "Ghi lại vào file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json(r'dataset/post_url_temp.json',orient='records')\n",
    "json_str = json.dumps(df.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'dataset/post_url.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4267878",
   "metadata": {},
   "source": [
    "#### 3.2. Thu thập thông tin của từng bài post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6815e9",
   "metadata": {},
   "source": [
    "Tách thành nhiều file url nhỏ để dễ xử lý hơn khi các link thu thập bị lỗi (có thể do người đăng bài post đó xóa bài, lỗi khi thu thập url, lỗi do truy cập vào trang web quá nhiều, mạng lag,...)\n",
    "\n",
    "Ở đây em tách thành 29 file url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf85518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[0:1000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3210f76",
   "metadata": {},
   "source": [
    "Thu thập thông tin của từng bài post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4458591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_01.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf0049",
   "metadata": {},
   "source": [
    "**Tương tự**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e89c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[1000:2000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_02.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[2000:3000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_03.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[3000:4000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec55b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_04.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651598ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[4000:5000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b416f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_05.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[5000:6000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec99760",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_06.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[6000:7000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_07.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[7000:8000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d87479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_08.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[8000:9000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed43888",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_09.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3cd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[9000:10000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d61d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_10.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b665bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[10000:11000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c9f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_11.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[11000:12000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_12.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[12000:13000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a291ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_13.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e780459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[13000:14000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dfb352",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_14.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[14000:15000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_15.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b516cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[15000:16000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ce776",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_16.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b86096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[16000:17000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_17.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[17000:18000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_18.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[18000:19000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_19.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28446bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[19000:20000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_20.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[20000:25000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71497d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_21.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[25000:30000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229bb1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_22.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4998b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[30000:35000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a1e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_23.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[35000:40000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f536fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_24.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[40000:45000,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8aaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_25.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[45000:,:]\n",
    "print(df1.shape)\n",
    "\n",
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e660a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_26.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e971da8",
   "metadata": {},
   "source": [
    "**Xử lý các file url chứa url bị lỗi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a8035",
   "metadata": {},
   "source": [
    "Thu thập lại từ những phần bị lỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec26fb",
   "metadata": {},
   "source": [
    "- 03\n",
    "\n",
    "- 13\n",
    "\n",
    "- 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd207936",
   "metadata": {},
   "source": [
    "Ta sẽ cào lại những trên khoảng url bị lỗi và chỉ cào những url chưa được cào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341743c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[2000:3000,:]\n",
    "df2= pd.read_json('dataset/post_info_03.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d748fa",
   "metadata": {},
   "source": [
    "- Tìm những url chưa được cào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d12503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames and specify the 'indicator' parameter\n",
    "df_merged = df1.merge(df2, on='link', how='outer', indicator=True)\n",
    "\n",
    "# Select rows where the '_merge' column is 'left_only'\n",
    "df_filtered = df_merged[df_merged['_merge'] == 'left_only']\n",
    "\n",
    "# Drop  some column\n",
    "#df_filtered.drop(columns=['_merge'], inplace=True)\n",
    "df1=pd.DataFrame(df_filtered['link'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ebc7b",
   "metadata": {},
   "source": [
    "- Ghi đè lại vào file url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee02d3",
   "metadata": {},
   "source": [
    "- Cào dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95588c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_27.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc599245",
   "metadata": {},
   "source": [
    "**Tương tự**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[12000:13000,:]\n",
    "df2= pd.read_json('dataset/post_info_13.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a122152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames and specify the 'indicator' parameter\n",
    "df_merged = df1.merge(df2, on='link', how='outer', indicator=True)\n",
    "\n",
    "# Select rows where the '_merge' column is 'left_only'\n",
    "df_filtered = df_merged[df_merged['_merge'] == 'left_only']\n",
    "\n",
    "# Drop  some column\n",
    "#df_filtered.drop(columns=['_merge'], inplace=True)\n",
    "df1=pd.DataFrame(df_filtered['link'])\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485138fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b677d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_28.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bd99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df1 = df1.iloc[30000:35000,:]\n",
    "df2= pd.read_json('dataset/post_info_23.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb203e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DataFrames and specify the 'indicator' parameter\n",
    "df_merged = df1.merge(df2, on='link', how='outer', indicator=True)\n",
    "\n",
    "# Select rows where the '_merge' column is 'left_only'\n",
    "df_filtered = df_merged[df_merged['_merge'] == 'left_only']\n",
    "\n",
    "# Drop  some column\n",
    "#df_filtered.drop(columns=['_merge'], inplace=True)\n",
    "df1=pd.DataFrame(df_filtered['link'])\n",
    "\n",
    "\n",
    "df1 = df1.loc[df1['link'] != 'https://phongtro123.com/tinh-thanh/ho-chi-minh/hinh-thachi-minh/phong-tro-nha-nguyen-can-cao-cap-moi-100-mat-tien-pham-the-hien.html']\n",
    "df1 = df1.loc[df1['link'] != \"https://phongtrot-phong-3-5tr-wc-trong-phong-moi-xay-cua-so-lon-gio-tu-do-q11.html\"]\n",
    "# Print the resulting DataFrame\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa7fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps(df1.to_dict('records'), ensure_ascii=False)\n",
    "with open(r'post_url_temp.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2528d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy crawl phongtro123_get_info -o dataset/post_info_29.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067401b5",
   "metadata": {},
   "source": [
    "**Merge toàn bộ file post_info (từ 01 - 29) thành 1 file post_info.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db524d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the contents of the JSON files into strings\n",
    "json_strs = [open(f'dataset/post_info_{i:02d}.json', 'r').read() for i in range(1, 30)]\n",
    "\n",
    "# Deserialize the JSON strings into Python objects\n",
    "objects = [json.loads(json_str) for json_str in json_strs]\n",
    "\n",
    "# Merge the objects into a single object\n",
    "# Merge the objects into a single object\n",
    "data_merged = []\n",
    "for obj in objects:\n",
    "    for key in obj:\n",
    "        data_merged.append(key)\n",
    "\n",
    "# Serialize the merged object into a JSON string\n",
    "json_str = json.dumps(data_merged,indent=2)\n",
    "\n",
    "# Write the JSON string to a new file\n",
    "with open('dataset/post_info.json', 'w') as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0c0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac4515a7",
   "metadata": {},
   "source": [
    "### 4. Kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9d6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng link đã thu thập:  49121\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('dataset/post_url.json')\n",
    "print(\"Số lượng link đã thu thập: \",df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740c648b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng thông tin giá thuê đã thu thập:  49119\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('dataset/post_info.json')\n",
    "print(\"Số lượng thông tin giá thuê đã thu thập: \",df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd73823",
   "metadata": {},
   "source": [
    "Số lượng thông tin đã thu thập có chênh lệch so số lượng link thu thập là do thời gian để thu thập toàn bộ dữ liệu tương đối lâu, và trong thời gian đó đã có thể có bài post bị xóa, hoặc link bị lỗi khi thực hiện bước thu thập url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88190e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('dataset/post_url.json')\n",
    "df2= pd.read_json('dataset/post_info.json')\n",
    "\n",
    "df_merged = df1.merge(df2, on='link', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ba71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các link bị lỗi:  ['https://phongtro123.com/tinh-thanh/ho-chi-minh/hinh-thachi-minh/phong-tro-nha-nguyen-can-cao-cap-moi-100-mat-tien-pham-the-hien.html', 'https://phongtrot-phong-3-5tr-wc-trong-phong-moi-xay-cua-so-lon-gio-tu-do-q11.html']\n"
     ]
    }
   ],
   "source": [
    "print('Các link bị lỗi: ' ,list(df_merged[df_merged['_merge'] == 'left_only']['link']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
